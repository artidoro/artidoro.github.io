---
layout: archive
title: "Projects"
permalink: /projects/
author_profile: true
---

Below is a short description of the research projects that I have been working on most recently.

1. Fine-tuning classical ML models using backpropagation
(current MSR project)
Besides contributing to the development of ML.NET at Microsoft, which is my full-time responsibility, I am working with two MSR researchers on exploring ways to improve accuracy and scoring speed of classical ML pipelines. Motivated by the fact that algorithms in an ML pipeline tend to be optimized independently, and that many classical ML algorithms construct solutions greedily we propose a methodology for fine-tuning ML pipelines by translating them into neural networks. Each algorithm in the pipeline is translated into a neural network module, and the modules are combined in a DAG which is trained with back propagation. We have implemented a prototype framework using PyTorch on top of ML.NET and its python bindings (Nimbus ML), and our experiments show that the fine-tuning of an ML pipeline using backpropagation improves prediction accuracy. Our framework allows varying degrees of relaxation of the origin classical ML algorithms, and we are currently exploring whether the improvements can be achieved while maintaining the model interpretability that comes with classical ML algorithms. We are currently also evaluating by how much hardware accelerators (e.g., GPUs) improve scoring performance of translated ML pipelines. Traditionally sequential algorithms such as decision trees can be translated in three-layer neural networks regardless of their original depth. 

2. PAC learning guarantees under covariate shift
(final project for CS 228 Computational Learning Theory with Prof. Valiant, and personal research)
During my first two months at Microsoft, in my free time, I have continued working on a project that I started at Harvard with a classmate. We worked on the Domain Adaptation problem, also known as the covariate shift problem, where the distributions that generate the training and test data differ while retaining the same labeling function. This problem occurs across a large range of practical applications, and is related to the more general challenge of transfer learning. Most recent work on the topic focuses on  optimization techniques that are specific to an algorithm or practical use case rather than a more general approach. The sparse literature attempting to provide general bounds seems to suggest that efficient learning even under strong assumptions is not possible for covariate shift. Our main contribution was to recontextualize these results by showing that any Probably Approximately Correct (PAC) learnable concept class is still PAC learnable under covariate shift conditions with only a polynomial increase in the number of training samples. This approach essentially demonstrates that the Domain Adaptation learning problem is as hard as the underlying PAC learning problem, provided some conditions over the training and test distributions. We also presented bounds for the rejection sampling algorithm, justifying it as a solution to the Domain Adaptation problem in certain scenarios. We submitted this paper to CIAC 2019, and it is currently under review.

3. Generating newspaper headlines by editing prototypes
(final project for CS281 Advanced Machine Learning with Prof. Rush)
I worked in collaboration with two students on exploring a recently proposed method for text generation. In September, Guu et al \cite{DBLP:journals/corr/abs-1709-08878} from Stanford proposed an innovative approach to text generation which consists in editing prototype sentences. This study only developed the probabilistic model to generate random sentences, which is not very useful in practice but is enough to demonstrate the technique. We explored the use of this technique to generate headlines of given news articles. Our probabilistic models is a conditional version of the model presented by Guu et al. and its implementation relies on a conditional variational autoencoder (VAE). This work did not produce exceptional results, however, it highlighted that neural VAEs are not well understood in the conditional setting. This led us to isolate this aspect of the problem and further explore it in another research project.

4. Conditional variational autoencoder for neural machine translation
(final project for CS287 NLP with Prof. Rush, and Harvard NLP lab)
Following the prototype editing project, we focused on exploring the performance of latent variable models for conditional text generation in the context of neural machine translation (NMT). As part of this project we build a neural translation system with attention like the one presented by Bahdanau et al. \cite{bahdanau}.
Similar to \cite{vnmt}, we augmented the encoder-decoder NMT paradigm by introducing a continuous latent variable to model features of the translation process. Our first contribution was to extend this model with a co-attention mechanism motivated by \cite{parikh} in the inference network. Compared to the vision domain, latent variable models for text face additional challenges due to the discrete nature of language, namely posterior collapse \cite{bowman}. We experimented with different approaches to mitigate this issue and reported the results.
We finally showed that our conditional variational model improves upon both discriminative attention-based translation and the variational baseline presented in \cite{vnmt}. Finally, we presented some exploration of the learned latent space to illustrate what the latent variable is capable of capturing.

5. Taint tracking for web assembly
(final project for CS263 Security Systems with Prof. Mickens)
This semester I am developing a taint tracking tool for web assembly. The objective of my work is to track the flow of sensitive information during the execution of web assembly and ensure that it is not leaked to untrusted sources. Dynamic tainting is a technique that tracks the influence of certain inputs (taint sources) through execution and is a powerful tool for information flow analysis and security. Although web assembly is becoming widely used, no taint tracking tool currently exists for it. I have built a web assembly virtual machine in Java Script to run in a browser, and will now modify it to include information flow analysis.

6. Scheduling algorithm for parallel processors
(final project for CS224 Advanced Algorithms with Prof. Nelson)
I worked in collaboration with two other students on the project, junior fall. We analyzed the Multiprocessors Scheduling Problem. We described several approaches used in the literature to solve this NP hard problem. We explored an approximation algorithm, and then an algorithm that finds the optimal result. In particular, we derived the (2 − 1/m)OPT bound on the list scheduling algorithm proposed by Graham \cite{graham:list} . We then analyzed the Branch-and-Bound method proposed by Fernandez \cite{fernandez} and Fujita \cite{fujita}, correcting two mistakes in Fujita’s exposition of the algorithm and simplifying the explanation of the math. We implemented and numerically tested the Branch-and-Bound algorithm, with both the Fernandez bound and the Fujita bound. Experiments were performed on data generated with RanGen, a tool specifically designed for benchmark tests of scheduling algorithms. With both bounds the algorithm obtained OPT in a few seconds on job dependency graphs (DAGs) of up to 150 nodes. Our tests demonstrated that Fujita produces better lower bounds than Fernandez in general. We showed however, that this improvement does not justify the increase in computation time, and that Fernandez achieves better overall completion time.

7. Reinforcement learning self-balancing robot
(final project for CS182 Artificial Intelligence with Prof. Kuindersma)
Junior fall, I worked on a self balancing robot which used reinforcement learning to balance itself. The traditional technique for this task, and my first attempt, was to discretize the state space and to learn the optimal action for each tile in the state space. This approach requires a lot of training episodes, and performed very well on simulators. On the physical robot however, this method did not work due to the limited number of episodes that could be run in a reasonable amount of time. I therefore found in the literature an alternative approach which relied on Q-Learning and a Fourier series basis function to approximate the value of an action at any given point in the state space. This technique greatly improved the efficiency of the learning process as it only required to learn the coefficients of the Fourier basis. The algorithm required fewer iterations than the previous approach to reach the self balancing behavior and worked on the physical robot.


8. Automated placement of components for PCBs
(summer research project at Cadence Design Systems under supervision of Taylor Hogan)
During the summer of 2015 (sophomore summer), I developed a method to automate and  optimize the disposition of components on printed circuit boards. The method relies on a hierarchical clustering of highly connected components. At each level components of a cluster are disposed using a placing algorithm that combines a genetic algorithm with simulated annealing. The placements are finetuned with an algorithm modeling connections with attractive forces. This was the first project in which I was given a lot of freedom. It was my first exposure to the design of printed circuit board and also the first time I had to interface my work with industrial representation tools. Despite these initial difficulties, the project gave very promising results. The designs obtained with my method were comparable to boards designed by actual engineers. The company filed three patent with my name on this representation and algorithm. One of the things that struck me most was to see the number of different themes in computer science that converged in the project. Clustering, data structures, algorithms and optimization methods although studied separately were all interdependent in the project. This experience left me with the desire to take more advanced courses and explore the fields in computer science that I had encountered. 
